{"cells":[{"cell_type":"code","execution_count":48,"id":"a9daf186","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","\n","# Create a Spark session instance\n","spark = SparkSession.builder.appName(\"SparkApp\").getOrCreate()"]},{"cell_type":"code","execution_count":49,"id":"bc59c1bd","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|\n","+---------------+------------+------------+------------+\n","|            1.0|       151.0|       239.0|        9.95|\n","|            1.0|       239.0|       246.0|        16.3|\n","|            3.0|       236.0|       236.0|         5.8|\n","|            5.0|       193.0|       193.0|        7.55|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            5.0|       193.0|       193.0|       13.31|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            1.0|       163.0|       229.0|        9.05|\n","|            1.0|       229.0|         7.0|        18.5|\n","|            2.0|       141.0|       234.0|        13.0|\n","+---------------+------------+------------+------------+\n","only showing top 10 rows\n","\n"]}],"source":["# Task 1\n","\n","# Read CSV\n","csv_path = \"gs://dataproc-staging-us-central1-591640780369-xk68flkr/data/2019-01-h1_cut (1).csv\"\n","\n","# LRead csv file into Spark dataframe\n","df = spark.read.csv(csv_path, header=True, inferSchema=True)\n","\n","# Select columns\n","columns_df = df.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"total_amount\")\n","\n","# Show the first 10 rows\n","columns_df.show(10)\n"]},{"cell_type":"code","execution_count":50,"id":"96d01a76","metadata":{"scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 141:============================>                            (1 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["There are 268536 rows in the training set, and 67314 in the test set\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# Task 2\n","\n","# Split the dataset for training and testing\n","trainDF, testDF = columns_df.randomSplit([.8,.2], seed=42)\n","\n","# Print trainDF and testDF\n","print(f\"\"\"There are {trainDF.count()} rows in the training set, and {testDF.count()} in the test set\"\"\")"]},{"cell_type":"code","execution_count":51,"id":"4e725994","metadata":{},"outputs":[],"source":["# Task 3\n","\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.regression import DecisionTreeRegressor\n","\n","# Assemble the three features into a single column\n","assembler = VectorAssembler(inputCols=[\"passenger_count\", \"pulocationid\", \"dolocationid\"],outputCol=\"features\")\n","\n","# Create Decision Tree Regressor\n","dt = DecisionTreeRegressor(featuresCol=\"features\",labelCol=\"total_amount\")"]},{"cell_type":"code","execution_count":52,"id":"c3336c85","metadata":{},"outputs":[],"source":["# Task 4\n","\n","from pyspark.ml import Pipeline\n","\n","# Create pipeline with assembler and decision tree\n","pipeline = Pipeline(stages=[assembler, dt])"]},{"cell_type":"code","execution_count":53,"id":"06c538e0","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# Task 5\n","\n","# Train the model\n","model = pipeline.fit(trainDF)"]},{"cell_type":"code","execution_count":46,"id":"65df9377","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+------------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|        prediction|\n","+---------------+------------+------------+------------+------------------+\n","|            0.0|         4.0|         4.0|        5.75|21.582862669245657|\n","|            0.0|         4.0|        90.0|        10.8| 18.70489820600742|\n","|            0.0|         4.0|        90.0|        15.8| 18.70489820600742|\n","|            0.0|         7.0|         7.0|         3.3|21.582862669245657|\n","|            0.0|         7.0|        48.0|       21.95| 18.70489820600742|\n","|            0.0|         7.0|       161.0|        15.8| 18.70489820600742|\n","|            0.0|         7.0|       260.0|        10.8| 18.70489820600742|\n","|            0.0|        13.0|        13.0|         5.8|21.582862669245657|\n","|            0.0|        13.0|        90.0|        16.3| 18.70489820600742|\n","|            0.0|        13.0|       100.0|       19.55| 18.70489820600742|\n","+---------------+------------+------------+------------+------------------+\n","only showing top 10 rows\n","\n"]}],"source":["# Task 6\n","\n","# Make predictions\n","predictions = model.transform(testDF)\n","\n","# Show the first 10 predictions\n","predictions.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"total_amount\", \"prediction\").show(10)"]},{"cell_type":"code","execution_count":47,"id":"58e987fb","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 134:>                                                        (0 + 1) / 2]\r","\r","[Stage 134:============================>                            (1 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["RMSE value = 67.05009053259988\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# Task 7\n","\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","# Initialize the evaluator for RMSE\n","regressionEvaluator = RegressionEvaluator(predictionCol=\"prediction\",labelCol=\"total_amount\",metricName=\"rmse\")\n","\n","# Calculate RMSE on the test set\n","rmse = regressionEvaluator.evaluate(predictions)\n","\n","# Print the RMSE\n","print(f\"RMSE value = {rmse}\")\n"]},{"cell_type":"code","execution_count":null,"id":"033e28a8","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}